{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the datasets for keras\n",
    "\n",
    "##### Fashion mnist datasets\n",
    "\n",
    "Link  https://keras.io/datasets/#fashion-mnist-database-of-fashion-articles\n",
    "\n",
    "Dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. The class labels are:\n",
    "\n",
    "| Label |\tDescription |\n",
    "--- | --- |\n",
    "| 0\t| T-shirt/top\n",
    "| 1\t| Trouser\n",
    "| 2\t| Pullover\n",
    "| 3\t| Dress\n",
    "| 4\t| Coat\n",
    "| 5\t| Sandal\n",
    "| 6\t| Shirt\n",
    "| 7\t| Sneaker\n",
    "| 8\t| Bag\n",
    "| 9\t| Ankle boot\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "### Usage:\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "> (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "Returns:\n",
    "2 tuples:\n",
    "1. x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 28, 28).\n",
    "2. y_train, y_test: uint8 array of labels (integers in range 0-9) with shape (num_samples,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x244e44359c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train_full[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-shirt/top'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train_full[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,  11, 142, 200, 106,   0,   0,\n",
       "          0,   0,   0,   0,   0,  85, 185, 112,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 152, 214, 217, 194, 236, 216, 187,\n",
       "        149, 135, 153, 211, 217, 231, 205, 217, 188,  34,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  66, 185, 166, 180, 181, 190, 211, 221,\n",
       "        197, 146, 198, 206, 191, 168, 190, 172, 188, 175,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 135, 153, 160, 175, 180, 170, 186, 187,\n",
       "        190, 188, 190, 187, 174, 195, 185, 174, 161, 175,  59,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 161, 147, 160, 170, 178, 177, 180, 168,\n",
       "        173, 174, 171, 185, 184, 185, 172, 171, 164, 174, 120,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   2, 175, 146, 145, 168, 178, 181, 185, 180,\n",
       "        184, 178, 179, 187, 191, 193, 190, 181, 171, 172, 158,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  35, 177, 155, 140, 151, 172, 191, 187, 186,\n",
       "        187, 186, 187, 182, 191, 194, 188, 180, 161, 161, 185,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  59, 170, 153, 141, 120, 154, 160, 161, 172,\n",
       "        168, 166, 161, 165, 172, 170, 164, 139, 149, 162, 166,  21,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  79, 145, 160, 214, 123, 128, 153, 160, 164,\n",
       "        158, 157, 154, 155, 170, 165, 141, 195, 193, 152, 166,  61,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 100, 157, 225, 245, 175, 113, 174, 158, 158,\n",
       "        160, 155, 160, 164, 178, 188, 135, 185, 240, 201, 172, 108,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  31, 174,  28, 126, 153, 166, 152, 158,\n",
       "        158, 160, 161, 157, 168, 191, 188,  18, 132, 159,   7,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  82, 187, 159, 153, 157,\n",
       "        158, 162, 164, 164, 154, 187, 190,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   1,   3,   5,   0,  37, 175, 158, 155, 162,\n",
       "        158, 160, 162, 165, 153, 177, 205,   0,   0,   3,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0,  25, 175, 152, 160, 158,\n",
       "        161, 160, 164, 164, 161, 166, 200,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   4,   0,  30, 171, 147, 164, 155,\n",
       "        165, 161, 165, 162, 170, 164, 162,   0,   0,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   4,   0,  57, 166, 155, 164, 166,\n",
       "        161, 161, 164, 167, 165, 165, 162,  28,   0,   3,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   3,   0, 114, 161, 161, 166, 159,\n",
       "        168, 161, 161, 172, 162, 165, 171,  50,   0,   5,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0, 149, 157, 167, 172, 159,\n",
       "        172, 164, 161, 172, 170, 160, 171,  89,   0,   4,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0,   4, 171, 164, 166, 173, 159,\n",
       "        179, 166, 160, 174, 167, 162, 166, 128,   0,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   0,  18, 152, 173, 160, 179, 154,\n",
       "        181, 166, 164, 175, 170, 166, 170, 164,   0,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0,  47, 165, 172, 167, 185, 153,\n",
       "        187, 173, 165, 174, 179, 166, 166, 158,   5,   0,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0,  87, 180, 162, 179, 179, 157,\n",
       "        191, 182, 165, 168, 190, 173, 165, 166,  20,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0, 105, 187, 157, 194, 175, 161,\n",
       "        190, 184, 170, 158, 205, 177, 168, 171,  44,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 138, 181, 158, 205, 160, 167,\n",
       "        190, 198, 167, 152, 218, 186, 170, 172,  57,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 135, 174, 167, 199, 155, 166,\n",
       "        201, 219, 165, 158, 218, 188, 167, 175,  56,   0,   7,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 129, 171, 172, 177, 153, 159,\n",
       "        206, 216, 148, 157, 206, 190, 165, 175,  48,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 167, 187, 182, 198, 194, 200,\n",
       "        226, 240, 184, 206, 255, 197, 178, 179,  42,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   0, 115, 135, 113, 106,  85,  82,\n",
       "        108, 133,  83,  90, 121, 120, 110, 158,  18,   0,   3,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "This is done to achieve the same scale in the data dimention. Since we know the range of our data which 0-255 thus we divide the data with 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sca = X_train_full / 255.\n",
    "X_test_sca = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train, valdation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_sca[:5000], X_train_sca[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# Assigning X_test_sca to X_test\n",
    "X_test_sca = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
       "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
       "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
       "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
       "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
       "        0.50980392, 0.28235294, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
       "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
       "        0.34509804, 0.6745098 , 0.25882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
       "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
       "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
       "        0.76862745, 0.89803922, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
       "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
       "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
       "        0.96078431, 0.67843137, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
       "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
       "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
       "        0.95294118, 0.79215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
       "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
       "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
       "        0.77254902, 0.81960784, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
       "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
       "        0.46666667, 0.65490196, 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
       "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
       "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
       "        0.81960784, 0.36078431, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
       "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
       "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
       "        1.        , 0.30196078, 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
       "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
       "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
       "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
       "        0.95686275, 0.62352941, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
       "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
       "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
       "        0.93333333, 0.84313725, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
       "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
       "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
       "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
       "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
       "        0.90980392, 0.96470588, 0.        ],\n",
       "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
       "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
       "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
       "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
       "        0.89411765, 0.88235294, 0.        ],\n",
       "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
       "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
       "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
       "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
       "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
       "        0.87843137, 0.89803922, 0.11372549],\n",
       "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
       "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
       "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
       "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
       "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
       "        0.86666667, 0.90196078, 0.2627451 ],\n",
       "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
       "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
       "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
       "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
       "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
       "        0.80392157, 0.80784314, 0.45098039],\n",
       "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
       "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
       "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
       "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
       "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
       "        0.69411765, 0.82352941, 0.36078431],\n",
       "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
       "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
       "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
       "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
       "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
       "        0.84705882, 0.66666667, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
       "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
       "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
       "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
       "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crete the model architecture\n",
    "There are two APIs for defining a model in keras:\n",
    "* Sequential model API: It is simple and it is use to create layer by layer model. All output of the previous layers are connected to the input of next layer\n",
    "\n",
    "* Funtional API: It is for a complex model. It is recommended when input will be supplied as difference layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to achieve the result \n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28])) # Flatten is used to convert the 28x28 array of the dataset to pixel\n",
    "model.add(keras.layers.Dense(300, activation='relu')) # 300 rep the neurons \n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the parameters using get_weight() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02448617, -0.00877795, -0.02189048, ..., -0.02766046,\n",
       "         0.03859074, -0.06889391],\n",
       "       [ 0.00476504, -0.03105379, -0.0586676 , ...,  0.00602964,\n",
       "        -0.02763776, -0.04165364],\n",
       "       [-0.06189284, -0.06901957,  0.07102345, ..., -0.04238207,\n",
       "         0.07121518, -0.07331658],\n",
       "       ...,\n",
       "       [-0.03048757,  0.02155137, -0.05400612, ..., -0.00113463,\n",
       "         0.00228987,  0.05581069],\n",
       "       [ 0.07061854, -0.06960931,  0.07038955, ..., -0.00384101,\n",
       "         0.00034875,  0.02878492],\n",
       "       [-0.06022581,  0.01577859, -0.02585464, ..., -0.00527829,\n",
       "         0.00272203, -0.06793761]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the dataset\n",
    "Note:\n",
    "\n",
    "The 'loss' value is chosen because y data is in form of label, that is wee have 10 labels e.g boot etc.\n",
    "\n",
    "sgd: Stochastic Gradient Descent, this is telling keras to do Back propagation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 17s 306us/sample - loss: 0.7226 - accuracy: 0.7641 - val_loss: 0.5073 - val_accuracy: 0.8320\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 10s 182us/sample - loss: 0.4844 - accuracy: 0.8323 - val_loss: 0.4538 - val_accuracy: 0.8488\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.4414 - accuracy: 0.8463 - val_loss: 0.4377 - val_accuracy: 0.8506\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 9s 167us/sample - loss: 0.4130 - accuracy: 0.8548 - val_loss: 0.4153 - val_accuracy: 0.8562\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 9s 158us/sample - loss: 0.3927 - accuracy: 0.8617 - val_loss: 0.3815 - val_accuracy: 0.8638\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 8s 138us/sample - loss: 0.3769 - accuracy: 0.8667 - val_loss: 0.3723 - val_accuracy: 0.8678\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 9s 159us/sample - loss: 0.3625 - accuracy: 0.8727 - val_loss: 0.3699 - val_accuracy: 0.8702\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.3516 - accuracy: 0.8745 - val_loss: 0.3660 - val_accuracy: 0.8702\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 9s 156us/sample - loss: 0.3419 - accuracy: 0.8773 - val_loss: 0.3437 - val_accuracy: 0.8792\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 7s 131us/sample - loss: 0.3324 - accuracy: 0.8811 - val_loss: 0.3514 - val_accuracy: 0.8766\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 11s 197us/sample - loss: 0.3240 - accuracy: 0.8840 - val_loss: 0.3367 - val_accuracy: 0.8810\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 9s 169us/sample - loss: 0.3160 - accuracy: 0.8872 - val_loss: 0.3319 - val_accuracy: 0.8834\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 11s 195us/sample - loss: 0.3073 - accuracy: 0.8905 - val_loss: 0.3319 - val_accuracy: 0.8828\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 9s 160us/sample - loss: 0.3017 - accuracy: 0.8922 - val_loss: 0.3240 - val_accuracy: 0.8856\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 9s 172us/sample - loss: 0.2953 - accuracy: 0.8937 - val_loss: 0.3170 - val_accuracy: 0.8892\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.2899 - accuracy: 0.8963 - val_loss: 0.3246 - val_accuracy: 0.8886\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 8s 148us/sample - loss: 0.2834 - accuracy: 0.8991 - val_loss: 0.3166 - val_accuracy: 0.8916\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 8s 138us/sample - loss: 0.2782 - accuracy: 0.8999 - val_loss: 0.3102 - val_accuracy: 0.8898\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 8s 154us/sample - loss: 0.2730 - accuracy: 0.9022 - val_loss: 0.3179 - val_accuracy: 0.8844\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 8s 139us/sample - loss: 0.2680 - accuracy: 0.9039 - val_loss: 0.3206 - val_accuracy: 0.8850\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 8s 150us/sample - loss: 0.2634 - accuracy: 0.9046 - val_loss: 0.2998 - val_accuracy: 0.8950\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.2577 - accuracy: 0.9070 - val_loss: 0.3100 - val_accuracy: 0.8884\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 8s 150us/sample - loss: 0.2539 - accuracy: 0.9089 - val_loss: 0.3000 - val_accuracy: 0.8914\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 8s 146us/sample - loss: 0.2492 - accuracy: 0.9104 - val_loss: 0.3105 - val_accuracy: 0.8838\n",
      "Epoch 25/30\n",
      "34176/55000 [=================>............] - ETA: 2s - loss: 0.2428 - accuracy: 0.9128"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(X_train, y_train, epochs=30,\n",
    "                         validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.imshow(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
