{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, cross_val_predict\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Performing Data Cleaning and Analysis\n",
    "<!-- #### 1. Understanding meaning of each column: -->\n",
    "<!-- <br>Data Dictionary: -->\n",
    "<br>**Variable        Description**</br>\n",
    "1. Survived\t- Survived (1) or died (0)\n",
    "2. Pclass -\tPassenger’s class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "3. Name\t- Passenger’s name\n",
    "4. Sex -\tPassenger’s sex\n",
    "5. Age\t- Passenger’s age\n",
    "6. SibSp -\tNumber of siblings/spouses aboard\n",
    "7. Parch -\tNumber of parents/children aboard (Some children travelled only with a nanny, therefore parch=0 for them.)\n",
    "8. Ticket -\tTicket number\n",
    "9. Fare -\tFare\n",
    "10. Cabin -\tCabin\n",
    "11. Embarked -\tPort of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deleting the columns not required for determining the survival of a person\n",
    "\"\"\"\n",
    "\n",
    "del train['PassengerId']\n",
    "del train['Ticket']\n",
    "del train['Fare']\n",
    "del train['Cabin']\n",
    "del train['Name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deleting the columns not required for determining the survival of a person for the data stored in test.csv\n",
    "\"\"\"\n",
    "\n",
    "del test['Ticket']\n",
    "del test['Fare']\n",
    "del test['Cabin']\n",
    "del test['Name']\n",
    "\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#We will create a new column called \"Gender\" and\n",
    "#fill it with values 1 ,2 based on the values of sex column in which male = 1 and female = 2\n",
    "\n",
    "def getNum(str):\n",
    "    if str == 'male':\n",
    "        return '1'\n",
    "    if str == 'female':\n",
    "        return '2'\n",
    "\n",
    "train['Gender'] = train['Sex'].apply(getNum)\n",
    "print(train.head())\n",
    "\n",
    "print(\"#\"*50)\n",
    "\n",
    "test['Gender'] = test['Sex'].apply(getNum)\n",
    "\n",
    "# Delete the Sex columns\n",
    "del train['Sex']\n",
    "del test['Sex']\n",
    "\n",
    "#Renaming \"gender\" column\n",
    "train.rename(columns={'Gender':'Sex'}, inplace=True)\n",
    "\n",
    "test.rename(columns={'Gender':'Sex'}, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analyzing Data by Visualization\n",
    "\n",
    "Inorder to understand who would have had a better probability of survival, we should visualize the patients who survived based on age, passenger class and etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "age_hist = sns.FacetGrid(train, col='Survived')\n",
    "age_hist.map(plt.hist, 'Age')\n",
    "age_hist.set_ylabels('Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Number of people who survived using the age and passenger class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pclass_age_grid = sns.FacetGrid(train, col='Survived', row='Pclass', height=2.0, aspect=1.6)\n",
    "pclass_age_grid.map(plt.hist, 'Age', alpha=0.5, bins=20)\n",
    "pclass_age_grid.add_legend()\n",
    "pclass_age_grid.set_ylabels('Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Handling the NULL values in the column Age\n",
    "\n",
    "#### We have NULL value inplace of Age for some of the people in both training and testing data.\n",
    "#### So, one way is to fill them with the mean values i.e. fill the ones who have survived with the mean age of the survived people and similarly fill those who haven't survived with the mean age of all non-survived people.\n",
    "\n",
    "#### But, this will only solve the problem for the training data and not for the testing data as we have to predict their survival status.\n",
    "\n",
    "#### So, we can tackle the issue by creating an array that contains random numbers, which are computed based on the mean age value in regard to the standard deviation and is_null.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# finding average survived age\n",
    "age_sur_mean = train[train.Survived==1]['Age'].mean()\n",
    "\n",
    "age_sur_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The avarage age of survived is 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the mean age of \"Not Survived\" people\n",
    "age_nsur_mean = train[train.Survived==0]['Age'].mean()\n",
    "\n",
    "age_nsur_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Solving the null values in Age column\n",
    "\n",
    "data = [train, test]\n",
    "for data_point in data:\n",
    "    mean = train['Age'].mean()\n",
    "    std = test[\"Age\"].std()\n",
    "    is_null = data_point['Age'].isnull().sum()\n",
    "\n",
    "    # compute the random range of age where mean-std, mean+std and is_null -> (start, high, size)\n",
    "    random_age = np.random.randint(mean - std, mean + std, size=is_null)\n",
    "\n",
    "    # Fill the random_age into NaN in Age columns\n",
    "    age_copy = data_point['Age'].copy()\n",
    "    age_copy[np.isnan(age_copy)] = random_age\n",
    "    data_point['Age'] = age_copy\n",
    "    data_point['Age'] = train['Age'].astype(int)\n",
    "\n",
    "train['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Since there are ONLY 2 rows whose Embarked data is not known,\n",
    "therefore we can neglect those 2 rows by dropping them as they will not make much of a difference\"\"\"\n",
    "\n",
    "# Removing the 2 rows having null value for Embarked column\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Grouping the Age data\n",
    "\n",
    "#### The age groups need to be converted into different sub-groups so that better prediction model can be formed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['Age'].min())\n",
    "print(train['Age'].max())\n",
    "print(train['Age'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data=[train,test]\n",
    "\n",
    "for data_point in data:\n",
    "    data_point.loc[ data_point['Age'] <= 10, 'Age'] = 0\n",
    "    data_point.loc[(data_point['Age'] > 10) & (data_point['Age'] <= 20), 'Age'] = 1\n",
    "    data_point.loc[(data_point['Age'] > 20) & (data_point['Age'] <= 30), 'Age'] = 2\n",
    "    data_point.loc[(data_point['Age'] > 30) & (data_point['Age'] <= 40), 'Age'] = 3\n",
    "    data_point.loc[(data_point['Age'] > 40) & (data_point['Age'] <= 50), 'Age'] = 4\n",
    "    data_point.loc[(data_point['Age'] > 50) & (data_point['Age'] <= 60), 'Age'] = 5\n",
    "    data_point.loc[(data_point['Age'] > 60) & (data_point['Age'] <= 70), 'Age'] = 6\n",
    "    data_point.loc[ data_point['Age'] > 70 , 'Age'] = 7\n",
    "\n",
    "train['Age'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train, test]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map({'C': 0, 'S': 1, 'Q': 2}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Probability of Survived to other features\n",
    "\n",
    "Like Pclass, Gender, SibSp, Parch etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Embarked', \"Survived\"]].groupby(['Embarked']).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train[['Age', 'Survived']].groupby(['Age']).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train[['Pclass', 'Survived']].groupby(['Pclass']).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train[['Sex', 'Survived']].groupby(['Sex']).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train[['Parch', 'Survived']].groupby(['Parch']).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[['SibSp', 'Survived']].groupby(['SibSp']).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Observation is that 'Parent/children' and 'Sibling/Spouse' can be combine to make 'Relative' in which column family_members will be created.\n",
    "\"\"\"\n",
    "\n",
    "# Combine the columns 'Parch' and 'SibSp' as 'Family_Member'\n",
    "\n",
    "train['Family_Member'] = train['Parch'] + train['SibSp'] + 1\n",
    "test['Family_Member'] = test['Parch'] + test['SibSp'] + 1\n",
    "\n",
    "del train['Parch']\n",
    "del train['SibSp']\n",
    "del test['Parch']\n",
    "del test['SibSp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(train.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(test.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "\n",
    "The correlation matrix revealed that the features in our dataset are not correlated which mean they are fit for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building Models for Prediction\n",
    "\n",
    "#### Now we will train multiple Machine Learning algorithms over the training data to predict the survival on our testing data and analyze the results thus obtained.\n",
    "\n",
    "#### We might also use use cross-validation in the end.\n",
    "\n",
    "####  We know that since the survival is represented as either 0 or 1, therefore it is a Classification problem. The algorithms used for the same are:\n",
    "##### Logistic Regression\n",
    "##### Support Vector Machines\n",
    "##### KNN or K-Nearest Neighbors\n",
    "##### Decision Trees\n",
    "##### Random Forest\n",
    "##### Stochastic Gradient descent (SGD)\n",
    "##### Gaussian Naive Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train.drop(['Survived'], axis = 1)\n",
    "y_train = train['Survived']\n",
    "\n",
    "x_test = test.drop('PassengerId', axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "turned_param = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4],\n",
    "                 'penalty' : ['l1', 'l2', 'none', 'elasticnet'],\n",
    "                'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}]\n",
    "#Using GridSearch\n",
    "log_reg = GridSearchCV(LogisticRegression(), turned_param, scoring = 'accuracy')\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "print(log_reg.best_estimator_)\n",
    "#print(model.score(x_test))\n",
    "\n",
    "pred = log_reg.predict(x_test)\n",
    "\n",
    "log_reg_acc = round(log_reg.score(x_train,y_train)*100, 2)\n",
    "print('Accuracy: ', log_reg_acc,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "#### Cross-Validation protects against overfitting.\n",
    "#### It is a resampling method which tells us how well our model would generalize to unseen data. This is achieved by fixing a number of partitions of the dataset called folds, predicting each fold separately, and averaging the predictions in the end.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our robust cross-validation scheme!\n",
    "kf = KFold(n_splits = 5, random_state = 2)\n",
    "\n",
    "# Print CV accuracy estimate:\n",
    "#print(cross_val_score(logisticRegression, X_test, y_test, cv = kf).mean())\n",
    "scores= cross_val_score(log_reg, x_train, y_train, cv = kf, scoring='f1')\n",
    "\n",
    "mean_acc_log = scores.mean()*100\n",
    "\n",
    "print('Scores: ', scores*100, '%')\n",
    "print('Mean: ', mean_acc_log, '%')\n",
    "print('Standard Deviation: ', scores.std()*100, '%\\n')\n",
    " \n",
    "pred= cross_val_predict(log_reg, x_train, y_train, cv=kf)\n",
    "print('Confusion Matrix: \\n' ,confusion_matrix(y_train, pred),'\\n')\n",
    "\n",
    "print(\"Precision: \", round(precision_score(y_train, pred)*100, 2),'%')\n",
    "print(\"Recall: \", round(recall_score(y_train, pred)*100, 2), '%')\n",
    "print('F1 Score: ', round(f1_score(y_train, pred)*100, 2), '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating odd list of K values\n",
    "my_K_list = list(range(0, 30))\n",
    "neighbors = list(filter(lambda x: x%2 != 0, my_K_list))\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# Perform K-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, x_train, y_train, cv=3, scoring='f1')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# changing to misclassification error\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k =neighbors[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal number of neighbors is %d.' % optimal_k)\n",
    "\n",
    "# Plotting misclassification error vs optimal_k\n",
    "plt.plot(neighbors, MSE)\n",
    "\n",
    "for xy in zip(neighbors, np.round(MSE, 3)):\n",
    "    plt.annotate('(%s, %s)' % xy, xy=xy, textcoords='data')\n",
    "\n",
    "plt.xlabel('Number of Neighbors k')\n",
    "plt.ylabel('Misclassification Error')\n",
    "plt.show()\n",
    "\n",
    "print('The misclassification error for each k value is :', np.round(MSE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ============================== KNN with k = optimal_k ===============================================\n",
    "# instantiate learning model k = optimal_k\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "\n",
    "# fitting the model with\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# predict the response\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_acc = round(knn.score(x_train, y_train)*100, 2)\n",
    "\n",
    "print(\"Accuracy:\", knn_acc, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print CV accuracy estimate:\n",
    "scores = cross_val_score(KNeighborsClassifier(), x_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "mean_acc_knn = scores.mean()*100\n",
    "\n",
    "print('Scores: ', scores*100, '%')\n",
    "print('Mean: ', mean_acc_knn, '%')\n",
    "print('Standard Deviation: ', scores.std()*100, '%\\n')\n",
    "\n",
    "knn_pred = cross_val_predict(knn, x_train, y_train, cv=kf)\n",
    "\n",
    "cm = confusion_matrix(y_train, knn_pred)\n",
    "ax = sns.heatmap(cm, square=True, annot=True, cbar=False, fmt='d')\n",
    "#ax.xaxis.set_ticklabels(fon )\n",
    "ax.set_xlabel('Actual Label', fontsize=13)\n",
    "ax.set_ylabel('Predicted Label', fontsize=13)\n",
    "\n",
    "print(\"Precision: \", round(precision_score(y_train, knn_pred)*100, 2),'%')\n",
    "print(\"Recall: \", round(recall_score(y_train, knn_pred)*100, 2), '%')\n",
    "print('F1 Score: ', round(f1_score(y_train, knn_pred)*100, 2), '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Decision Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "tree_pred = tree.predict(x_test)\n",
    "tree_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking accuracy of Decision Tree model\n",
    "\n",
    "tree_acc = round(tree.score(x_train, y_train)*100, 3)\n",
    "print('Accuracy:',tree_acc,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CV_Tree\n",
    "scores = cross_val_score(DecisionTreeClassifier(), x_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "mean_acc_tree = scores.mean() * 100\n",
    "\n",
    "print('Scores: ', scores*100, '%')\n",
    "print('Mean: ', mean_acc_tree, '%')\n",
    "print('Standard Deviation: ', scores.std()*100, '%\\n')\n",
    "\n",
    "pred_tree = cross_val_predict(tree, x_train, y_train, cv=kf)\n",
    "\n",
    "\n",
    "print(\"Precision: \", round(precision_score(y_train, pred_tree)*100, 2),'%')\n",
    "print(\"Recall:  \", round(recall_score(y_train, pred_tree)*100, 2), '%')\n",
    "print('F1 Score: ', round(f1_score(y_train, pred_tree)*100, 2), '%')\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_train, pred_tree)\n",
    "ax = sns.heatmap(cm, square=True, annot=True, cbar=False, fmt='d')\n",
    "#ax.xaxis.set_ticklabels()\n",
    "ax.set_xlabel('Actual Label', fontsize=13)\n",
    "ax.set_ylabel('Predicted Label', fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=30)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "pred_rf = rf.predict(x_test)\n",
    "\n",
    "print(pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking accuracy of the Random Forest Classifier\n",
    "\n",
    "#rf.score(X_train, y_train)\n",
    "acc_rf = round(rf.score(x_train, y_train) * 100, 3)\n",
    "print(\"Accuracy\", acc_rf,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV_Tree\n",
    "scores = cross_val_score(RandomForestClassifier(), x_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "mean_acc_rf = scores.mean() * 100\n",
    "\n",
    "print('Scores: ', scores*100, '%')\n",
    "print('Mean: ', mean_acc_rf, '%')\n",
    "print('Standard Deviation: ', scores.std()*100, '%\\n')\n",
    "\n",
    "pred_rf = cross_val_predict(rf, x_train, y_train, cv=kf)\n",
    "\n",
    "\n",
    "print(\"Precision: \", round(precision_score(y_train, pred_tree)*100, 2),'%')\n",
    "print(\"Recall:  \", round(recall_score(y_train, pred_tree)*100, 2), '%')\n",
    "print('F1 Score: ', round(f1_score(y_train, pred_tree)*100, 2), '%')\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_train, pred_rf)\n",
    "ax = sns.heatmap(cm, square=True, annot=True, cbar=False, fmt='d')\n",
    "#ax.xaxis.set_ticklabels()\n",
    "ax.set_xlabel('Actual Label', fontsize=13)\n",
    "ax.set_ylabel('Predicted Label', fontsize=13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (Support Vector Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "svc.fit(x_train, y_train)\n",
    "svc_pred = svc.predict(x_test)\n",
    "\n",
    "svc_acc = round(svc.score(x_train, y_train)*100, 2)\n",
    "\n",
    "print('Accuracy: ',svc_acc , '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV_Tree\n",
    "scores = cross_val_score(SVC(), x_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "mean_acc_svc = scores.mean() * 100\n",
    "\n",
    "print('Scores: ', scores*100, '%')\n",
    "print('Mean: ', mean_acc_svc, '%')\n",
    "print('Standard Deviation: ', scores.std()*100, '%\\n')\n",
    "\n",
    "pred_svc  = cross_val_predict(svc, x_train, y_train, cv=kf)\n",
    "\n",
    "\n",
    "print(\"Precision: \", round(precision_score(y_train, pred_svc)*100, 2),'%')\n",
    "print(\"Recall:  \", round(recall_score(y_train, pred_svc)*100, 2), '%')\n",
    "print('F1 Score: ', round(f1_score(y_train, pred_svc)*100, 2), '%')\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_train, pred_svc)\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.heatmap(cm, square=True, annot=True, cbar=False, fmt='d')\n",
    "ax.xaxis.set_ticklabels([\"False\",\"True\"], fontsize = 12)\n",
    "ax.yaxis.set_ticklabels([\"False\",\"True\"], fontsize = 12, rotation=0)\n",
    "ax.set_xlabel('Actual Label', fontsize=13)\n",
    "ax.set_ylabel('Predicted Label', fontsize=13)\n",
    "plt.show()\n",
    "\n",
    "print('Confusion Matrix: \\n' ,confusion_matrix(y_train, pred_svc),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = GaussianNB() \n",
    "gaussian.fit(x_train, y_train)  \n",
    "\n",
    "y_pred = gaussian.predict(x_test)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking accuracy for the Gaussian Naive Bayes model\n",
    "\n",
    "acc_gaussian = round(gaussian.score(x_train, y_train) * 100, 2)\n",
    "print(acc_gaussian,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print CV accuracy estimate:\n",
    "#print(cross_val_score(GaussianNB() , X_test, y_test, cv = kf).mean())\n",
    "\n",
    "scores= cross_val_score(GaussianNB() , x_train, y_train, cv = kf, scoring='f1')\n",
    "\n",
    "mean_acc_gau = scores.mean()*100\n",
    "\n",
    "print('Scores: ', scores*100, '%')\n",
    "print('Mean: ', mean_acc_gau, '%')\n",
    "print('Standard Deviation: ', scores.std()*100, '%\\n')\n",
    "\n",
    "#Confusion Matrix\n",
    "pred= cross_val_predict(gaussian, x_train, y_train, cv=kf)\n",
    "\n",
    "print(\"Precision: \", round(precision_score(y_train, pred)*100, 2),'%')\n",
    "print(\"Recall: \", round(recall_score(y_train, pred)*100, 2), '%')\n",
    "print('F1 Score: ', round(f1_score(y_train, pred)*100, 2), '%')\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_train, pred)\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.heatmap(cm, square=True, annot=True, cbar=False, fmt='d')\n",
    "ax.xaxis.set_ticklabels([\"False\",\"True\"], fontsize = 12)\n",
    "ax.yaxis.set_ticklabels([\"False\",\"True\"], fontsize = 12, rotation=0)\n",
    "ax.set_xlabel('Actual Label', fontsize=13)\n",
    "ax.set_ylabel('Predicted Label', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bag_clf = BaggingClassifier(base_estimator=tree, n_estimators=2000,\n",
    "                            bootstrap=True, n_jobs=-1,\n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagg_clf_pred = bag_clf.predict(x_train)\n",
    "\n",
    "bagg_acc = round(bag_clf.score(x_train, y_train)*100, 2)\n",
    "print('Accuracy: ',bagg_acc , '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV_Tree\n",
    "#scores = cross_val_score(BaggingClassifier(), x_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "bag_pred = cross_val_predict(BaggingClassifier(), x_train, y_train, cv=kf)\n",
    "\n",
    "mean_acc_bag = scores.mean()*100\n",
    "\n",
    "print('Scores: ', scores*100, '%')\n",
    "print('Mean: ', mean_acc_bag, '%')\n",
    "print('Standard Deviation: ', scores.std()*100, '%\\n')\n",
    "\n",
    "print(\"Precision: \", round(precision_score(y_train, bag_pred)*100, 2),'%')\n",
    "print(\"Recall:  \", round(recall_score(y_train, bag_pred)*100, 2), '%')\n",
    "print('F1 Score: ', round(f1_score(y_train, bag_pred)*100, 2), '%')\n",
    "\n",
    "#Confusion Matrix\n",
    "pred= cross_val_predict(bag_clf, x_train, y_train, cv=kf)\n",
    "cm = confusion_matrix(y_train, pred)\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.heatmap(cm, square=True, annot=True, cbar=False, fmt='d')\n",
    "ax.xaxis.set_ticklabels([\"False\",\"True\"], fontsize = 12)\n",
    "ax.yaxis.set_ticklabels([\"False\",\"True\"], fontsize = 12, rotation=0)\n",
    "ax.set_xlabel('Actual Label', fontsize=13)\n",
    "ax.set_ylabel('Predicted Label', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(learning_rate =0.02, n_estimators =5000)#%%\n",
    "\n",
    "ada_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ada = ada_clf.predict(x_train)\n",
    "\n",
    "ada_acc = round(ada_clf.score(x_train, y_train)*100, 2)\n",
    "print('Accuracy: ', ada_acc, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print CV accuracy estimate:\n",
    "#print(cross_val_score(GaussianNB() , X_test, y_test, cv = kf).mean())\n",
    "\n",
    "scores= cross_val_score(AdaBoostClassifier() , x_train, y_train, cv = kf, scoring='f1')\n",
    "\n",
    "mean_acc_ada = scores.mean()*100\n",
    "\n",
    "print('Scores: ', scores*100, '%')\n",
    "print('Mean: ', mean_acc_ada, '%')\n",
    "print('Standard Deviation: ', scores.std()*100, '%\\n')\n",
    "\n",
    "print(\"Precision: \", round(precision_score(y_train, pred)*100, 2),'%')\n",
    "print(\"Recall: \", round(recall_score(y_train, pred)*100, 2), '%')\n",
    "print('F1 Score: ', round(f1_score(y_train, pred)*100, 2), '%')\n",
    "\n",
    "#Confusion Matrix\n",
    "pred= cross_val_predict(ada_clf, x_train, y_train, cv=kf)\n",
    "cm = confusion_matrix(y_train, pred)\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.heatmap(cm, square=True, annot=True, cbar=False, fmt='d')\n",
    "ax.xaxis.set_ticklabels([\"False\",\"True\"], fontsize = 12)\n",
    "ax.yaxis.set_ticklabels([\"False\",\"True\"], fontsize = 12, rotation=0)\n",
    "ax.set_xlabel('Actual Label', fontsize=13)\n",
    "ax.set_ylabel('Predicted Label', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Finding the Best Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Mean Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>83.010</td>\n",
       "      <td>82.457945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>86.389</td>\n",
       "      <td>79.869866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>86.389</td>\n",
       "      <td>78.970990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <td>83.350</td>\n",
       "      <td>76.719990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>81.100</td>\n",
       "      <td>73.886835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <td>79.980</td>\n",
       "      <td>72.049361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <td>86.390</td>\n",
       "      <td>72.049361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>79.530</td>\n",
       "      <td>70.395898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy Score  Mean Score\n",
       "Model                                              \n",
       "Support Vector Machines          83.010   82.457945\n",
       "Random forest                    86.389   79.869866\n",
       "Decision Tree                    86.389   78.970990\n",
       "K-Nearest Neighbors              83.350   76.719990\n",
       "AdaBoost                         81.100   73.886835\n",
       "Gaussian Naive Bayes             79.980   72.049361\n",
       "Bagging Classifier               86.390   72.049361\n",
       "Logistic Regression              79.530   70.395898"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Support Vector Machines', 'K-Nearest Neighbors', 'Decision Tree', 'Random forest', 'Gaussian Naive Bayes', 'Bagging Classifier', 'AdaBoost'],\n",
    "    'Accuracy Score': [log_reg_acc, svc_acc, knn_acc, tree_acc, acc_rf, acc_gaussian, bagg_acc, ada_acc],\n",
    "    'Mean Score': [mean_acc_log, mean_acc_svc, mean_acc_knn, mean_acc_tree, mean_acc_rf, mean_acc_gau, mean_acc_bag, mean_acc_ada]\n",
    "})\n",
    "df_result = results.sort_values(by='Mean Score', ascending=False)\n",
    "df_result = df_result.set_index('Model')\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}